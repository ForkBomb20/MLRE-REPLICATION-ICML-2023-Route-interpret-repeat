{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62668722",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b4b559ef703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./codebase\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\n",
    "    os.path.abspath(\"./codebase\")\n",
    ")\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import one_hot\n",
    "import sklearn.metrics as metrics\n",
    "import utils\n",
    "from Explainer.loss_F import loss_fn_kd, entropy_loss\n",
    "from Explainer.models.Gated_Logic_Net import Gated_Logic_Net\n",
    "from Explainer.models.explainer import Explainer\n",
    "from Explainer.models.pi import Pi\n",
    "from dataset.dataset_cubs import Dataset_cub_for_explainer\n",
    "from dataset.utils_dataset import get_dataset_with_image_and_attributes\n",
    "from Explainer.loss_F import loss_fn_kd, entropy_loss, Selective_Distillation_Loss\n",
    "from Explainer.models.concepts import Conceptizator\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c99aa8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './out/cub/explainer/ResNet101/lr_0.01_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_0.2_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none/cov_0.2_lr_0.01/iter8/explainer/test_explainer_configs.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      2\u001b[0m cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m pickle_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./out/cub/explainer/ResNet101/lr_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcov\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcov_0.2_lr_0.01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miter8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_explainer_configs.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m args \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(pickle_in)\n\u001b[1;32m     14\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args\u001b[38;5;241m.\u001b[39mlabels)\n",
      "File \u001b[0;32m~/miniconda3/envs/cub_resnet_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './out/cub/explainer/ResNet101/lr_0.01_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_0.2_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none/cov_0.2_lr_0.01/iter8/explainer/test_explainer_configs.pkl'"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        \"iter8\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr)\n",
    "print(args.cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07dba8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './out/cub/explainer/ResNet101/lr_0.01_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_0.2_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none/iter1/explainer/test_explainer_configs.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m      2\u001b[0m cov \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m pickle_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./out/cub/explainer/ResNet101/lr_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcov\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miter1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_explainer_configs.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m args \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(pickle_in)\n\u001b[1;32m     13\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args\u001b[38;5;241m.\u001b[39mlabels)\n",
      "File \u001b[0;32m~/miniconda3/envs/cub_resnet_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './out/cub/explainer/ResNet101/lr_0.01_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_0.2_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none/iter1/explainer/test_explainer_configs.pkl'"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"iter1\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr)\n",
    "print(args.cov)\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    "    f\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\"\n",
    ")\n",
    "\n",
    "root = \"./out/cub/\"\n",
    "experiment = f\"explainer/ResNet101/{experiment_folder}\"\n",
    "iteration = \"iter1\"\n",
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "train_tensor_image_1 = torch.load(\n",
    "    os.path.join(\n",
    "        root, experiment, iteration, expert_type, output, \"train_tensor_images.pt\"\n",
    "    )\n",
    ")\n",
    "\n",
    "train_tensor_y_1 = torch.load(\n",
    "    os.path.join(\n",
    "        root, experiment, iteration, expert_type, output, \"train_tensor_y.pt\"\n",
    "    )\n",
    ")\n",
    "\n",
    "train_concept_mask_1 = torch.load(\n",
    "    os.path.join(root, experiment, iteration, expert_type, output, \"train_mask_alpha.pt\")\n",
    ")\n",
    "\n",
    "test_tensor_image_1 = torch.load(\n",
    "    os.path.join(\n",
    "        root, experiment, iteration, expert_type, output, \"test_tensor_images.pt\"\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_y_1 = torch.load(\n",
    "    os.path.join(\n",
    "        root, experiment, iteration, expert_type, output, \"test_tensor_y.pt\"\n",
    "    )\n",
    ")\n",
    "\n",
    "test_concept_mask_1 = torch.load(\n",
    "    os.path.join(root, experiment, iteration, expert_type, output, \"test_mask_alpha.pt\")\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Train sizes >>\")\n",
    "print(train_tensor_image_1.size())\n",
    "print(train_tensor_y_1.size())\n",
    "print(train_concept_mask_1.size())\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Test sizes >>\")\n",
    "print(test_tensor_image_1.size())\n",
    "print(test_tensor_y_1.size())\n",
    "print(test_concept_mask_1.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c21118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Train sizes >>\n",
      "torch.Size([1209, 3, 448, 448])\n",
      "torch.Size([1209])\n",
      "torch.Size([1209, 108])\n",
      "\n",
      "\n",
      " << Test sizes >>\n",
      "torch.Size([133, 3, 448, 448])\n",
      "torch.Size([133])\n",
      "torch.Size([133, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter2\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter2\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_2.size())\\nprint(train_tensor_y_2.size())\\nprint(train_mask_alpha_2.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_2.size())\\nprint(test_tensor_y_2.size())\\nprint(test_mask_alpha_2.size())\";\n                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter2\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter2\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_2 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_2.size())\\nprint(train_tensor_y_2.size())\\nprint(train_mask_alpha_2.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_2.size())\\nprint(test_tensor_y_2.size())\\nprint(test_mask_alpha_2.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        \"iter2\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    "    f\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\"\n",
    ")\n",
    "\n",
    "root = \"./out/cub/\"\n",
    "experiment = f\"explainer/ResNet101/{experiment_folder}\"\n",
    "iteration = \"iter2\"\n",
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "train_tensor_images_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_tensor_y_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_mask_alpha_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_tensor_images_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_y_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_mask_alpha_2 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Train sizes >>\")\n",
    "print(train_tensor_images_2.size())\n",
    "print(train_tensor_y_2.size())\n",
    "print(train_mask_alpha_2.size())\n",
    "\n",
    "print(\"\\n\\n << Test sizes >>\")\n",
    "print(test_tensor_images_2.size())\n",
    "print(test_tensor_y_2.size())\n",
    "print(test_mask_alpha_2.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8279cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Train sizes >>\n",
      "torch.Size([1292, 3, 448, 448])\n",
      "torch.Size([1292])\n",
      "torch.Size([1292, 108])\n",
      "\n",
      "\n",
      " << Test sizes >>\n",
      "torch.Size([153, 3, 448, 448])\n",
      "torch.Size([153])\n",
      "torch.Size([153, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter3\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter3\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_3.size())\\nprint(train_tensor_y_3.size())\\nprint(train_mask_alpha_3.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_3.size())\\nprint(test_tensor_y_3.size())\\nprint(test_mask_alpha_3.size())\";\n                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter3\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter3\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_3 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_3.size())\\nprint(train_tensor_y_3.size())\\nprint(train_mask_alpha_3.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_3.size())\\nprint(test_tensor_y_3.size())\\nprint(test_mask_alpha_3.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        \"iter3\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    "    f\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\"\n",
    ")\n",
    "\n",
    "root = \"./out/cub/\"\n",
    "experiment = f\"explainer/ResNet101/{experiment_folder}\"\n",
    "iteration = \"iter3\"\n",
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "train_tensor_images_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_tensor_y_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_mask_alpha_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_tensor_images_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_y_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_mask_alpha_3 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Train sizes >>\")\n",
    "print(train_tensor_images_3.size())\n",
    "print(train_tensor_y_3.size())\n",
    "print(train_mask_alpha_3.size())\n",
    "\n",
    "print(\"\\n\\n << Test sizes >>\")\n",
    "print(test_tensor_images_3.size())\n",
    "print(test_tensor_y_3.size())\n",
    "print(test_mask_alpha_3.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c321a0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Train sizes >>\n",
      "torch.Size([1292, 3, 448, 448])\n",
      "torch.Size([1292])\n",
      "torch.Size([1292, 108])\n",
      "\n",
      "\n",
      " << Test sizes >>\n",
      "torch.Size([176, 3, 448, 448])\n",
      "torch.Size([176])\n",
      "torch.Size([176, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter4\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter4\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_4.size())\\nprint(train_tensor_y_4.size())\\nprint(train_mask_alpha_4.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_4.size())\\nprint(test_tensor_y_4.size())\\nprint(test_mask_alpha_4.size())\";\n                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter4\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter4\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_4 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_4.size())\\nprint(train_tensor_y_4.size())\\nprint(train_mask_alpha_4.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_4.size())\\nprint(test_tensor_y_4.size())\\nprint(test_mask_alpha_4.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        \"iter4\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    "    f\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\"\n",
    ")\n",
    "\n",
    "root = \"./out/cub/\"\n",
    "experiment = f\"explainer/ResNet101/{experiment_folder}\"\n",
    "iteration = \"iter4\"\n",
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "train_tensor_images_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_tensor_y_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_mask_alpha_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_tensor_images_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_y_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_mask_alpha_4 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Train sizes >>\")\n",
    "print(train_tensor_images_4.size())\n",
    "print(train_tensor_y_4.size())\n",
    "print(train_mask_alpha_4.size())\n",
    "\n",
    "print(\"\\n\\n << Test sizes >>\")\n",
    "print(test_tensor_images_4.size())\n",
    "print(test_tensor_y_4.size())\n",
    "print(test_mask_alpha_4.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae38bdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Train sizes >>\n",
      "torch.Size([1139, 3, 448, 448])\n",
      "torch.Size([1139])\n",
      "torch.Size([1139, 108])\n",
      "\n",
      "\n",
      " << Test sizes >>\n",
      "torch.Size([146, 3, 448, 448])\n",
      "torch.Size([146])\n",
      "torch.Size([146, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter5\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter5\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_5.size())\\nprint(train_tensor_y_5.size())\\nprint(train_mask_alpha_5.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_5.size())\\nprint(test_tensor_y_5.size())\\nprint(test_mask_alpha_5.size())\";\n                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter5\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter5\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_5 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_5.size())\\nprint(train_tensor_y_5.size())\\nprint(train_mask_alpha_5.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_5.size())\\nprint(test_tensor_y_5.size())\\nprint(test_mask_alpha_5.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        \"iter5\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    "    f\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\"\n",
    ")\n",
    "\n",
    "root = \"./out/cub/\"\n",
    "experiment = f\"explainer/ResNet101/{experiment_folder}\"\n",
    "iteration = \"iter5\"\n",
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "train_tensor_images_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_tensor_y_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_mask_alpha_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_tensor_images_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_y_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_mask_alpha_5 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Train sizes >>\")\n",
    "print(train_tensor_images_5.size())\n",
    "print(train_tensor_y_5.size())\n",
    "print(train_mask_alpha_5.size())\n",
    "\n",
    "print(\"\\n\\n << Test sizes >>\")\n",
    "print(test_tensor_images_5.size())\n",
    "print(test_tensor_y_5.size())\n",
    "print(test_mask_alpha_5.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e56429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "0.01\n",
      "0.2\n",
      "\n",
      "\n",
      " << Train sizes >>\n",
      "torch.Size([1345, 3, 448, 448])\n",
      "torch.Size([1345])\n",
      "torch.Size([1345, 108])\n",
      "\n",
      "\n",
      " << Test sizes >>\n",
      "torch.Size([189, 3, 448, 448])\n",
      "torch.Size([189])\n",
      "torch.Size([189, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter6\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter6\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_6.size())\\nprint(train_tensor_y_6.size())\\nprint(train_mask_alpha_6.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_6.size())\\nprint(test_tensor_y_6.size())\\nprint(test_mask_alpha_6.size())\";\n                var nbb_formatted_code = \"base_lr = 0.01\\nbase_cov = 0.2\\npickle_in = open(\\n    os.path.join(\\n        f\\\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\\\",\\n        \\\"cov_0.2_lr_0.01\\\",\\n        \\\"iter6\\\",\\n        \\\"explainer\\\",\\n        \\\"test_explainer_configs.pkl\\\",\\n    ),\\n    \\\"rb\\\",\\n)\\nargs = pickle.load(pickle_in)\\nn_classes = len(args.labels)\\nx_to_bool = 0.5\\ntop_k_explanations = 50\\nconcept_names = args.concept_names\\nprint(\\\"########################\\\")\\nprint(args.lr[-1])\\nprint(args.cov[-1])\\n\\nuse_concepts_as_pi_input = True\\nexplainer_init = \\\"none\\\"\\n\\nexperiment_folder = (\\n    f\\\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\\\"\\n    f\\\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\\\"\\n    f\\\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\\\"\\n    f\\\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\\\"\\n    f\\\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\\\"\\n    f\\\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\\\"\\n)\\n\\nroot = \\\"./out/cub/\\\"\\nexperiment = f\\\"explainer/ResNet101/{experiment_folder}\\\"\\niteration = \\\"iter6\\\"\\nexpert_type = \\\"explainer\\\"\\noutput = \\\"g_outputs\\\"\\n\\n\\ntrain_tensor_images_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_images.pt\\\",\\n    )\\n)\\n\\ntrain_tensor_y_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_tensor_y.pt\\\",\\n    )\\n)\\n\\ntrain_mask_alpha_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"train_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\ntest_tensor_images_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_images.pt\\\",\\n    )\\n)\\n\\ntest_tensor_y_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_tensor_y.pt\\\",\\n    )\\n)\\n\\ntest_mask_alpha_6 = torch.load(\\n    os.path.join(\\n        root,\\n        experiment,\\n        \\\"cov_0.2_lr_0.01\\\",\\n        iteration,\\n        expert_type,\\n        output,\\n        \\\"test_mask_alpha.pt\\\",\\n    )\\n)\\n\\n\\nprint(\\\"\\\\n\\\\n << Train sizes >>\\\")\\nprint(train_tensor_images_6.size())\\nprint(train_tensor_y_6.size())\\nprint(train_mask_alpha_6.size())\\n\\nprint(\\\"\\\\n\\\\n << Test sizes >>\\\")\\nprint(test_tensor_images_6.size())\\nprint(test_tensor_y_6.size())\\nprint(test_mask_alpha_6.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_lr = 0.01\n",
    "base_cov = 0.2\n",
    "pickle_in = open(\n",
    "    os.path.join(\n",
    "        f\"./out/cub/explainer/ResNet101/lr_{base_lr}_epochs_500_temperature-lens_0.7_use-concepts-as-pi-input_True_input-size-pi_2048_cov_{base_cov}_alpha_0.5_selection-threshold_0.5_lambda-lens_0.0001_alpha-KD_0.9_temperature-KD_10.0_hidden-layers_1_layer_layer4_explainer_init_none\",\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        \"iter6\",\n",
    "        \"explainer\",\n",
    "        \"test_explainer_configs.pkl\",\n",
    "    ),\n",
    "    \"rb\",\n",
    ")\n",
    "args = pickle.load(pickle_in)\n",
    "n_classes = len(args.labels)\n",
    "x_to_bool = 0.5\n",
    "top_k_explanations = 50\n",
    "concept_names = args.concept_names\n",
    "print(\"########################\")\n",
    "print(args.lr[-1])\n",
    "print(args.cov[-1])\n",
    "\n",
    "use_concepts_as_pi_input = True\n",
    "explainer_init = \"none\"\n",
    "\n",
    "experiment_folder = (\n",
    "    f\"lr_{args.lr[0]}_epochs_{args.epochs}_temperature-lens_{args.temperature_lens}\"\n",
    "    f\"_use-concepts-as-pi-input_{use_concepts_as_pi_input}_input-size-pi_{args.input_size_pi}\"\n",
    "    f\"_cov_{args.cov[0]}_alpha_{args.alpha}_selection-threshold_{args.selection_threshold}\"\n",
    "    f\"_lambda-lens_{args.lambda_lens}_alpha-KD_{args.alpha_KD}\"\n",
    "    f\"_temperature-KD_{float(args.temperature_KD)}_hidden-layers_{len(args.hidden_nodes)}\"\n",
    "    f\"_layer_{args.layer}_explainer_init_{explainer_init if not args.explainer_init else args.explainer_init}\"\n",
    ")\n",
    "\n",
    "root = \"./out/cub/\"\n",
    "experiment = f\"explainer/ResNet101/{experiment_folder}\"\n",
    "iteration = \"iter6\"\n",
    "expert_type = \"explainer\"\n",
    "output = \"g_outputs\"\n",
    "\n",
    "\n",
    "train_tensor_images_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_tensor_y_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "train_mask_alpha_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"train_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_tensor_images_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_images.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_tensor_y_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_tensor_y.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "test_mask_alpha_6 = torch.load(\n",
    "    os.path.join(\n",
    "        root,\n",
    "        experiment,\n",
    "        \"cov_0.2_lr_0.01\",\n",
    "        iteration,\n",
    "        expert_type,\n",
    "        output,\n",
    "        \"test_mask_alpha.pt\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\\n << Train sizes >>\")\n",
    "print(train_tensor_images_6.size())\n",
    "print(train_tensor_y_6.size())\n",
    "print(train_mask_alpha_6.size())\n",
    "\n",
    "print(\"\\n\\n << Test sizes >>\")\n",
    "print(test_tensor_images_6.size())\n",
    "print(test_tensor_y_6.size())\n",
    "print(test_mask_alpha_6.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189f1b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8241, 3, 448, 448])\n",
      "torch.Size([8241])\n",
      "torch.Size([8241, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 11;\n                var nbb_unformatted_code = \"train_tensor_images = torch.cat(\\n    (train_tensor_image_1, train_tensor_images_2, train_tensor_images_3, train_tensor_images_4, \\n     train_tensor_images_5, train_tensor_images_6), dim=0\\n)\\ntrain_tensor_y = torch.cat(\\n    (train_tensor_y_1, train_tensor_y_2, train_tensor_y_3, train_tensor_y_4,\\n    train_tensor_y_5, train_tensor_y_6), dim=0\\n)\\ntrain_mask_alpha = torch.cat(\\n    (train_concept_mask_1, train_mask_alpha_2, train_mask_alpha_3, train_mask_alpha_4, train_mask_alpha_5,\\n    train_mask_alpha_6), dim=0\\n)\\n\\nprint(train_tensor_images.size())\\nprint(train_tensor_y.size())\\nprint(train_mask_alpha.size())\";\n                var nbb_formatted_code = \"train_tensor_images = torch.cat(\\n    (\\n        train_tensor_image_1,\\n        train_tensor_images_2,\\n        train_tensor_images_3,\\n        train_tensor_images_4,\\n        train_tensor_images_5,\\n        train_tensor_images_6,\\n    ),\\n    dim=0,\\n)\\ntrain_tensor_y = torch.cat(\\n    (\\n        train_tensor_y_1,\\n        train_tensor_y_2,\\n        train_tensor_y_3,\\n        train_tensor_y_4,\\n        train_tensor_y_5,\\n        train_tensor_y_6,\\n    ),\\n    dim=0,\\n)\\ntrain_mask_alpha = torch.cat(\\n    (\\n        train_concept_mask_1,\\n        train_mask_alpha_2,\\n        train_mask_alpha_3,\\n        train_mask_alpha_4,\\n        train_mask_alpha_5,\\n        train_mask_alpha_6,\\n    ),\\n    dim=0,\\n)\\n\\nprint(train_tensor_images.size())\\nprint(train_tensor_y.size())\\nprint(train_mask_alpha.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tensor_images = torch.cat(\n",
    "    (train_tensor_image_1, train_tensor_images_2, train_tensor_images_3, train_tensor_images_4, \n",
    "     train_tensor_images_5, train_tensor_images_6), dim=0\n",
    ")\n",
    "train_tensor_y = torch.cat(\n",
    "    (train_tensor_y_1, train_tensor_y_2, train_tensor_y_3, train_tensor_y_4,\n",
    "    train_tensor_y_5, train_tensor_y_6), dim=0\n",
    ")\n",
    "train_mask_alpha = torch.cat(\n",
    "    (train_concept_mask_1, train_mask_alpha_2, train_mask_alpha_3, train_mask_alpha_4, train_mask_alpha_5,\n",
    "    train_mask_alpha_6), dim=0\n",
    ")\n",
    "\n",
    "print(train_tensor_images.size())\n",
    "print(train_tensor_y.size())\n",
    "print(train_mask_alpha.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ef01132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1040, 3, 448, 448])\n",
      "torch.Size([1040])\n",
      "torch.Size([1040, 108])\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 12;\n                var nbb_unformatted_code = \"test_tensor_images = torch.cat(\\n    (test_tensor_image_1, test_tensor_images_2, test_tensor_images_3, test_tensor_images_4,\\n    test_tensor_images_5, test_tensor_images_6), dim=0\\n)\\ntest_tensor_y = torch.cat(\\n    (test_tensor_y_1, test_tensor_y_2, test_tensor_y_3, test_tensor_y_4, test_tensor_y_5, test_tensor_y_6), dim=0\\n)\\ntest_mask_alpha = torch.cat(\\n    (test_concept_mask_1, test_mask_alpha_2, test_mask_alpha_3, test_mask_alpha_4, test_mask_alpha_5,\\n    test_mask_alpha_6), dim=0\\n)\\n\\nprint(test_tensor_images.size())\\nprint(test_tensor_y.size())\\nprint(test_mask_alpha.size())\";\n                var nbb_formatted_code = \"test_tensor_images = torch.cat(\\n    (\\n        test_tensor_image_1,\\n        test_tensor_images_2,\\n        test_tensor_images_3,\\n        test_tensor_images_4,\\n        test_tensor_images_5,\\n        test_tensor_images_6,\\n    ),\\n    dim=0,\\n)\\ntest_tensor_y = torch.cat(\\n    (\\n        test_tensor_y_1,\\n        test_tensor_y_2,\\n        test_tensor_y_3,\\n        test_tensor_y_4,\\n        test_tensor_y_5,\\n        test_tensor_y_6,\\n    ),\\n    dim=0,\\n)\\ntest_mask_alpha = torch.cat(\\n    (\\n        test_concept_mask_1,\\n        test_mask_alpha_2,\\n        test_mask_alpha_3,\\n        test_mask_alpha_4,\\n        test_mask_alpha_5,\\n        test_mask_alpha_6,\\n    ),\\n    dim=0,\\n)\\n\\nprint(test_tensor_images.size())\\nprint(test_tensor_y.size())\\nprint(test_mask_alpha.size())\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_tensor_images = torch.cat(\n",
    "    (test_tensor_image_1, test_tensor_images_2, test_tensor_images_3, test_tensor_images_4,\n",
    "    test_tensor_images_5, test_tensor_images_6), dim=0\n",
    ")\n",
    "test_tensor_y = torch.cat(\n",
    "    (test_tensor_y_1, test_tensor_y_2, test_tensor_y_3, test_tensor_y_4, test_tensor_y_5, test_tensor_y_6), dim=0\n",
    ")\n",
    "test_mask_alpha = torch.cat(\n",
    "    (test_concept_mask_1, test_mask_alpha_2, test_mask_alpha_3, test_mask_alpha_4, test_mask_alpha_5,\n",
    "    test_mask_alpha_6), dim=0\n",
    ")\n",
    "\n",
    "print(test_tensor_images.size())\n",
    "print(test_tensor_y.size())\n",
    "print(test_mask_alpha.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0daa5a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./out/cub/completeness/ResNet101/dataset\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 13;\n                var nbb_unformatted_code = \"save_path = f\\\"./out/{args.dataset}/completeness/{args.arch}/dataset\\\"\\nos.makedirs(save_path, exist_ok=True)\\nprint(save_path)\\ntorch.save(train_tensor_images, os.path.join(save_path, f\\\"train_tensor_images.pt\\\"))\\ntorch.save(train_tensor_y, os.path.join(save_path, f\\\"train_tensor_y.pt\\\"))\\ntorch.save(train_mask_alpha, os.path.join(save_path, f\\\"train_mask_alpha.pt\\\"))\\n\\ntorch.save(test_tensor_images, os.path.join(save_path, f\\\"test_tensor_images.pt\\\"))\\ntorch.save(test_tensor_y, os.path.join(save_path, f\\\"test_tensor_y.pt\\\"))\\ntorch.save(test_mask_alpha, os.path.join(save_path, f\\\"test_mask_alpha.pt\\\"))\";\n                var nbb_formatted_code = \"save_path = f\\\"./out/{args.dataset}/completeness/{args.arch}/dataset\\\"\\nos.makedirs(save_path, exist_ok=True)\\nprint(save_path)\\ntorch.save(train_tensor_images, os.path.join(save_path, f\\\"train_tensor_images.pt\\\"))\\ntorch.save(train_tensor_y, os.path.join(save_path, f\\\"train_tensor_y.pt\\\"))\\ntorch.save(train_mask_alpha, os.path.join(save_path, f\\\"train_mask_alpha.pt\\\"))\\n\\ntorch.save(test_tensor_images, os.path.join(save_path, f\\\"test_tensor_images.pt\\\"))\\ntorch.save(test_tensor_y, os.path.join(save_path, f\\\"test_tensor_y.pt\\\"))\\ntorch.save(test_mask_alpha, os.path.join(save_path, f\\\"test_mask_alpha.pt\\\"))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = f\"./out/{args.dataset}/completeness/{args.arch}/dataset\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "print(save_path)\n",
    "torch.save(train_tensor_images, os.path.join(save_path, f\"train_tensor_images.pt\"))\n",
    "torch.save(train_tensor_y, os.path.join(save_path, f\"train_tensor_y.pt\"))\n",
    "torch.save(train_mask_alpha, os.path.join(save_path, f\"train_mask_alpha.pt\"))\n",
    "\n",
    "torch.save(test_tensor_images, os.path.join(save_path, f\"test_tensor_images.pt\"))\n",
    "torch.save(test_tensor_y, os.path.join(save_path, f\"test_tensor_y.pt\"))\n",
    "torch.save(test_mask_alpha, os.path.join(save_path, f\"test_mask_alpha.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cub_resnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
